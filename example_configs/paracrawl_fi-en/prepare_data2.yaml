common:

  output_directory: paracrawl_fi-en
  chunksize: 1000000

steps:

  # 1
  - type: opus_read
    parameters:
      corpus_name: ParaCrawl
      source_language: fi
      target_language: en
      release: v4
      preprocessing: raw
      src_output: sents.fi.gz
      tgt_output: sents.en.gz

  # 2
  - type: concatenate
    parameters:
      inputs:
      - sents.fi.gz
      - sents.en.gz
      output: concatenated.gz

  # 3
  - type: train_ngram
    parameters:
      data: concatenated.gz
      parameters:
        norder: 5
        dscale: 1
      model: bg.arpa.gz

  # 4
  - type: filter
    parameters:
      inputs: [sents.fi.gz, sents.en.gz]
      outputs: [filtered.fi.gz, filtered.en.gz]
      filters:
        - LengthFilter:
            unit: word
            min_length: 1
            max_length: 100

        - LengthRatioFilter:
            unit: word
            threshold: 3

        - LongWordFilter:
            threshold: 40

        - HtmlTagFilter: {}

        - CharacterScoreFilter:
            scripts: [Latin, Latin]
            thresholds: [1, 1]

  # 5
  - type: train_ngram
    parameters:
      data: filtered.fi.gz
      parameters:
        norder: 15
        dscale: 0.1
      model: fi.arpa.gz

  # 6
  - type: train_ngram
    parameters:
      data: filtered.en.gz
      parameters:
        norder: 15
        dscale: 0.1
      model: en.arpa.gz

  # 7
  - type: train_alignment
    parameters:
      src_data: filtered.fi.gz
      tgt_data: filtered.en.gz
      parameters:
        src_tokenizer: [moses, fi]
        tgt_tokenizer: [moses, en]
        model: 3
      output: align.priors

  # 8
  - type: subset
    parameters:
      inputs: [sents.fi.gz, sents.en.gz]
      outputs: [subset_100k.fi.gz, subset_100k.en.gz]
      seed: 123
      size: 100000

  # 9
  - type: subset
    parameters:
      inputs: [sents.fi.gz, sents.en.gz]
      outputs: [devset_100_1.fi.gz, devset_100_1.en.gz]
      seed: 1001
      size: 100

  # 10
  - type: subset
    parameters:
      inputs: [sents.fi.gz, sents.en.gz]
      outputs: [devset_100_2.fi.gz, devset_100_2.en.gz]
      seed: 1002
      size: 100

  # 11
  - type: score
    parameters:
      inputs: [subset_100k.fi.gz, subset_100k.en.gz]
      output: subset_100k-scores.fi-en.jsonl.gz
      filters: &scorefilt
        - LengthFilter:
            name: char
            unit: char

        - LengthFilter:
            name: word
            unit: word

        - LengthRatioFilter:
            name: char
            unit: char

        - LengthRatioFilter:
            name: word
            unit: word

        - LongWordFilter: {}

        - CharacterScoreFilter:
            scripts: [Latin, Latin]

        - LanguageIDFilter:
            name: langid
            id_method: langid
            languages: [fi, en]

        - LanguageIDFilter:
            name: cld2
            id_method: cld2
            languages: [fi, en]

        - TerminalPunctuationFilter: {}

        - NonZeroNumeralsFilter: {}

        - CrossEntropyFilter:
            lm_params:
              - filename: fi.arpa.gz
                interpolate:
                - [bg.arpa.gz, 0.01]
              - filename: en.arpa.gz
                interpolate:
                - [bg.arpa.gz, 0.01]

        - WordAlignFilter:
            src_tokenizer: [moses, fi]
            tgt_tokenizer: [moses, en]
            model: 3
            priors: align.priors

  # 12
  - type: score
    parameters:
      inputs: [devset_100_1.fi.gz, devset_100_1.en.gz]
      output: devset_100_1-scores.fi-en.jsonl.gz
      filters: *scorefilt

  # 13
  - type: score
    parameters:
      inputs: [devset_100_2.fi.gz, devset_100_2.en.gz]
      output: devset_100_2-scores.fi-en.jsonl.gz
      filters: *scorefilt

  # 14
  - type: score
    parameters:
      inputs: [sents.fi.gz, sents.en.gz]
      output: scores.fi-en.jsonl.gz
      filters: *scorefilt

  # requires devset_100_1_labels.jsonl in the current directory
  # - type: join
  #   parameters:
  #     inputs:
  #     - devset_100_1-scores.fi-en.jsonl.gz
  #     - ../devset_100_1_labels.jsonl
  #     output: devset_100_1-scores-and-labels.fi-en.jsonl.gz

  # requires devset_100_2_labels.jsonl in the current directory
  # - type: join
  #   parameters:
  #     inputs:
  #     - devset_100_2-scores.fi-en.jsonl.gz
  #     - ../devset_100_2_labels.jsonl
  #     output: devset_100_2-scores-and-labels.fi-en.jsonl.gz

  # - type: concatenate
  #   parameters:
  #     inputs:
  #     - devset_100_1-scores-and-labels.fi-en.jsonl.gz
  #     - devset_100_2-scores-and-labels.fi-en.jsonl.gz
  #     output: devset_100_concatenated.fi-en.jsonl.gz

  - type: sort
    parameters:
      inputs:
      - subset_100k.fi.gz
      - subset_100k.en.gz
      - subset_100k-scores.fi-en.jsonl.gz
      outputs:
      - subset_100k_sorted.fi.gz
      - subset_100k_sorted.en.gz
      - subset_100k-scores-sorted.fi-en.jsonl.gz
      values: subset_100k-scores.fi-en.jsonl.gz
      key:
      - CrossEntropyFilter.0
      - CrossEntropyFilter.1
      reverse: true

  - type: sort
    parameters:
      inputs:
      - sents.fi.gz
      - sents.en.gz
      - scores.fi-en.jsonl.gz
      outputs:
      - sents_sorted.fi.gz
      - sents_sorted.en.gz
      - scores_sorted.fi-en.jsonl.gz
      values: scores.fi-en.jsonl.gz
      key:
      - CrossEntropyFilter.0
      - CrossEntropyFilter.1
      combine_operator: add

